# -*- coding: utf-8 -*-
"""Conv1D Encoder Globe 244/244p.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nvYqiPexsAE5tJ81sfMMceqBWQClp3yb

#**Mount drive and imports**
"""
import pandas as pd
import numpy as np
import pygrib
from tqdm import tqdm

from sklearn import preprocessing

from tensorflow import keras
from keras.models import Model
from keras import models
import tensorflow as tf

import matplotlib.pyplot as plt
import matplotlib.colors

"""#**Data Preprocessing**"""

def create_pg(path):

  pygrib_data = pygrib.open(path)

  return pygrib_data

#define function to create variable df and temp
def create_df(pygrib_data):

  #parameters to extract from grib file
  parameters = ['pressure in hpa', 'gh', 't', 'u', 'v', 'icmr', 'rwmr', 'snmr', 'grle', 'w', 'dlwrf','dswrf', 'uswrf', 'ulwrf']

  data_vals = np.array(list(map(lambda x: x.data()[0],pygrib_data.select(shortName = parameters, typeOfLevel = ['isobaricInhPa'])[:]))).reshape((361, 720, -1))

  temp_vals = np.array([]).reshape(361, 720, 0)
  solar = np.array([]).reshape(361, 720, 0)

  #get surface data for temperature and solar flux
  for g in pygrib_data.select(shortName = parameters, typeOfLevel = ['surface'])[:]:
    data = np.array(g.data()[0]).reshape((361,720,1))
    
    #get surface temperature values
    if g['name'] == "Temperature":
      temp_vals = np.concatenate([temp_vals, data], 2)

    #add solar flux data from surface to data_vals
    else:
      solar = np.concatenate([solar, data], 2)

  #get all data values
  data_vals = np.concatenate([data_vals, solar],2)


  #create list (length 361) of dataframes by latitudes
  df_list = []

  for i in range(0, 361):
    df_list.append(pd.DataFrame(data_vals[i]))

  #add latitude
  for count, df_lat in enumerate(df_list):
    df_lat["241"] = count

  #add longitude
  for i in range(len(df_list)):
    df_list[i]["242"] = np.arange(len(df_list[i]))

  #combine all dataframes in list into 1 big dataframe
  df_raw = pd.concat(df_list)


  #create an array of rounded temperature values
  temp_vals = temp_vals.reshape(-1, 1)

  #add surface temperature values back to dataframe
  df_raw.insert(241, "241", temp_vals, allow_duplicates = True)

  #reindex columns
  df_raw.columns = list(range(0, df_raw.shape[1]))

  return df_raw

def create_labels(df_raw):

  dfrounded = df_raw.round()

  row_list = []
  for i in tqdm(range((dfrounded.shape[0])), desc = "Creating label arrays"):
    row_list.append(list(dfrounded.iloc[i, :]))

  array_labels = np.array(row_list)

  return array_labels

#define function to normalise all data variables
def normalise_df(df_raw):
  for i in tqdm(list(range(0, df_raw.shape[1])), desc = "Normalising df"):
    df_raw.iloc[:, i] = (df_raw.iloc[:, i] - min(df_raw.iloc[:, i]))/(max(df_raw.iloc[:, i]) - min(df_raw.iloc[:, i]))

  df_normalised = df_raw

  return df_normalised

#define function to reshape df into array for input into model
def reshaper(df_normalised):
  array_norm = df_normalised.to_numpy()
  array_norm_reshaped = array_norm.reshape(array_norm.shape[0], array_norm.shape[1], 1)

  return array_norm_reshaped

def preprocess_data(path):

  pygrib_data = create_pg(path)

  df_raw = create_df(pygrib_data)

  array_labels = create_labels(df_raw)
  df_normalised = normalise_df(df_raw)

  array_norm_reshaped = reshaper(df_normalised)

  return array_norm_reshaped, array_labels

#run before

path = "data/gfs_4_20200401_0000_003.grb2"

apr01_003_x, apr01_003_y = preprocess_data(path)

"""#**Conv1D 244Encoder Model**

##**Keras Functional Model Architecture**
"""

#244 parallel networks
inputs = keras.layers.Input(shape = (244, 1))

outputs = []

for i in range(0, 244):
  encoder_layer_1 = keras.layers.Conv1D(128, 2, activation = "relu", padding = "same")(inputs)
  encoder_layer_2 = keras.layers.Conv1D(64, 2, activation = "relu", padding = "same")(encoder_layer_1)
  flatten = keras.layers.Flatten()(encoder_layer_2)
  output_node = keras.layers.Dense(1)(flatten)
  outputs.append(output_node)

conv_encoder_244p = keras.Model(inputs = inputs, outputs = outputs)
conv_encoder_244p.compile(loss = "mse", optimizer = "adam", metrics = ["mae", "mse"])
conv_encoder_244p.summary()

#visualise model
# keras.utils.plot_model(conv_encoder_244p, "Conv1D Encoder 244 Parallel.png")

"""#**Train model on 1st timestep**"""

def fit_model(model_name, x, y, epochs = 30, batch_size = 64):

  history = model_name.fit(x, y, epochs = epochs, batch_size = batch_size)
  return history
apr01_003_y = apr01_003_y.reshape(-1, 244)
history = fit_model(conv_encoder_244p, apr01_003_x, np.split(apr01_003_y, 244, axis=1) , batch_size = 4)

# score = conv_encoder_244p.evaluate(apr01_006_x, apr01_006_y, verbose = 0)
# print('Test loss:', score[0])
# print('Test accuracy:', score[1])

#visualise loss for training on 1 timestep
plt.plot(history.history['loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['training loss'], loc='upper left')
plt.show()

#save the model
conv_encoder_244p.save("model/Conv1D Encoder 244 Parallel Model.h5")